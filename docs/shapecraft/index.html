<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <meta name="title" content="ShapeCraft: LLM Agents for Structured, Textured and Interactive 3D Modeling - Shuyuan Zhang, Chenhan Jiang, Zuoou Li, Jiankang Deng">
  <meta name="description" content="We introduce ShapeCraft, a novel training-free multi-agent framework that generates structured, textured, and interactive 3D models from natural language.">
  <meta name="keywords" content="ShapeCraft, LLM Agents, 3D Modeling, Text-to-3D, Generative AI, Training-free, Multi-agent Systems, Computer Vision, Graphics, AI Research">
  <meta name="author" content="Shuyuan Zhang, Chenhan Jiang, Zuoou Li, Jiankang Deng">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <!-- TODO: Replace with your institution or lab name | ask chenhan or jiankang about this-->
  <meta property="og:site_name" content="Imperial College London">
  <!-- TODO: Same as paper title above -->
  <meta property="og:title" content="ShapeCraft: LLM Agents for Structured, Textured and Interactive 3D Modeling">
  <!-- TODO: Same as description above -->
  <meta property="og:description" content="We introduce ShapeCraft, a novel training-free multi-agent framework that generates structured, textured, and interactive 3D models from natural language.">
  <!-- TODO: Replace with your actual website URL -->
  <meta property="og:url" content="https://sanbingyouyong.github.io/shapecraft/">
  <!-- TODO: Create a 1200x630px preview image and update path -->
  <meta property="og:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="ShapeCraft: LLM Agents for Structured, Textured and Interactive 3D Modeling - Research Preview">
  <!-- TODO: time?  -->
  <meta property="article:published_time" content="2024-01-01T00:00:00.000Z">
  <meta property="article:author" content="Shuyuan Zhang">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="ShapeCraft">
  <meta property="article:tag" content="LLM Agents">
  <!-- TODO: can we have this many? -->
  <meta property="article:tag" content="3D Modeling">
  <meta property="article:tag" content="Text-to-3D">
  <meta property="article:tag" content="Generative AI">
  <meta property="article:tag" content="Training-free">
  <meta property="article:tag" content="Multi-agent Systems">
  <meta property="article:tag" content="Computer Vision">
  <meta property="article:tag" content="Graphics">
  <meta property="article:tag" content="AI Research">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@imperialcollege">
  <!-- TODO: Replace with first author's Twitter handle | is this bad...? -->
  <meta name="twitter:creator" content="@RayZhangSBYY">
  <meta name="twitter:title" content="ShapeCraft: LLM Agents for Structured, Textured and Interactive 3D Modeling">
  <meta name="twitter:description" content="We introduce ShapeCraft, a novel training-free multi-agent framework that generates structured, textured, and interactive 3D models from natural language.">
  <!-- TODO: Same as social preview image above -->
  <meta name="twitter:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="ShapeCraft: LLM Agents for Structured, Textured and Interactive 3D Modeling - Research Preview">

  <!-- Academic/Research Specific -->
   <!-- TODO: check title to the final submission or arxiv -->
  <meta name="citation_title" content="ShapeCraft: LLM Agents for Structured, Textured and Interactive 3D Modeling">
  <meta name="citation_author" content="Zhang, Shuyuan">
  <meta name="citation_author" content="Jiang, Chenhan">
  <meta name="citation_author" content="Li, Zuoou">
  <meta name="citation_author" content="Deng, Jiankang">
  <meta name="citation_publication_date" content="2025">
  <!-- TODO: check full name? -->
  <meta name="citation_conference_title" content="NeurIPS 2025">
  <!-- TODO: pdf -->
  <meta name="citation_pdf_url" content="https://YOUR_DOMAIN.com/static/pdfs/paper.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <!-- TODO: Replace with your paper title and authors -->
  <title>ShapeCraft: LLM Agents for Structured, Textured and Interactive 3D Modeling - Shuyuan Zhang, Chenhan Jiang, Zuoou Li, Jiankang Deng | Academic Research</title>
  
  <!-- Favicon and App Icons -->
   <!-- TODO: update favicon -->
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
   <!-- TODO: check what date to use as publication date | and NeurIPS full nam? | abstract update? | social image | bibtex |  -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "ShapeCraft: LLM Agents for Structured, Textured and Interactive 3D Modeling",
    "description": "We introduce ShapeCraft, a novel training-free multi-agent framework that generates structured, textured, and interactive 3D models from natural language.",
    "author": [
      {
        "@type": "Person",
        "name": "Shuyuan Zhang",
        "affiliation": {
          "@type": "Organization",
          "name": "Imperial College London"
        }
      },
      {
        "@type": "Person",
        "name": "Chenhan Jiang",
        "affiliation": {
          "@type": "Organization",
          "name": "Hong Kong University of Science and Technology"
        }
      },
      {
        "@type": "Person",
        "name": "Zuoou Li",
        "affiliation": {
          "@type": "Organization",
          "name": "Imperial College London"
        }
      },
      {
        "@type": "Person",
        "name": "Jiankang Deng",
        "affiliation": {
          "@type": "Organization",
          "name": "Imperial College London"
        }
      }
    ],
    "datePublished": "2024-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "NeurIPS 2025"
    },
    "url": "https://sanbingyouyong.github.io/shapecraft/",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["ShapeCraft", "LLM Agents", "3D Modeling", "Text-to-3D", "Generative AI", "Training-free", "Multi-agent Systems", "Computer Vision", "Graphics", "AI Research"],
    "abstract": "3D generation from natural language offers significant potential to reduce expert manual modeling efforts and enhance accessibility to 3D assets. However, existing methods often yield unstructured meshes and exhibit poor interactivity, making them impractical for artistic workflows. To address these limitations, we represent 3D assets as shape programs and introduce ShapeCraft, a novel multi-agent framework for text-to-3D generation. At its core, we propose a Graph-based Procedural Shape (GPS) representation that decomposes complex natural language into a structured graph of sub-tasks, thereby facilitating accurate LLM comprehension and interpretation of spatial relationships and semantic shape details. Specifically, LLM agents hierarchically parse user input to initialize GPS, then iteratively refine procedural modeling and painting to produce structured, textured, and interactive 3D assets. Qualitative and quantitative experiments demonstrate ShapeCraft's superior performance in generating geometrically accurate and semantically rich 3D assets compared to existing LLM-based agents. We further show the versatility of ShapeCraft through examples of animated and user-customized editing, highlighting its potential for broader interactive applications.",
    "citation": "BIBTEX_CITATION_HERE",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://sanbingyouyong.github.io/shapecraft/"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "Text-to-3D Generation"
      },
      {
        "@type": "Thing", 
        "name": "LLM Agents"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "Imperial College London",
    "url": "https://www.imperial.ac.uk/",
    "logo": "https://YOUR_DOMAIN.com/static/images/favicon.ico",
    "sameAs": [
      "https://twitter.com/RayZhangSBYY",
      "https://github.com/SanBingYouYong"
    ]
  }
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <!-- NOTE: removed the more works drop down as I have none | TODO: ask chenhen or jiankang for more work ad here -->

  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <!-- TODO: Replace with your paper title -->
            <h1 class="title is-1 publication-title">ShapeCraft: LLM Agents for Structured, Textured and Interactive 3D Modeling</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://sanbingyouyong.github.io" target="_blank">Shuyuan Zhang</a><sup>1,*</sup>,</span>
              <span class="author-block">
                <a href="https://jiangchenhan.github.io/" target="_blank">Chenhan Jiang</a><sup>2,*</sup>,</span>
              <span class="author-block">
                <a href="https://leo9344.github.io/" target="_blank">Zuoou Li</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://jiankangdeng.github.io" target="_blank">Jiankang Deng</a><sup>1</sup></span>
            </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>Imperial College London<br><sup>2</sup>Hong Kong University of Science and Technology<br>NeurIPS 2025</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body has-text-centered">
            <img src="./static/images/teaser.png" alt="ShapeCraft Teaser" style="max-width:100%; height:auto;">
            <h2 class="subtitle has-text-centered">
                We introduce <b>ShapeCraft</b>, a novel training-free multi-agent framework that generates structured, textured, and interactive 3D models from natural language.
            </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <!-- TODO: check if we need to update the abstract -->
          <p>
            3D generation from natural language offers significant potential to reduce expert manual modeling efforts and enhance accessibility to 3D assets. However, existing methods often yield unstructured meshes and exhibit poor interactivity, making them impractical for artistic workflows. To address these limitations, we represent 3D assets as shape programs and introduce ShapeCraft, a novel multi-agent framework for text-to-3D generation.
          </p>
          <p>
            At its core, we propose a Graph-based Procedural Shape (GPS) representation that decomposes complex natural language into a structured graph of sub-tasks, thereby facilitating accurate LLM comprehension and interpretation of spatial relationships and semantic shape details. Specifically, LLM agents hierarchically parse user input to initialize GPS, then iteratively refine procedural modeling and painting to produce structured, textured, and interactive 3D assets.
          </p>
          <p>
            Qualitative and quantitative experiments demonstrate ShapeCraft's superior performance in generating geometrically accurate and semantically rich 3D assets compared to existing LLM-based agents. We further show the versatility of ShapeCraft through examples of animated and user-customized editing, highlighting its potential for broader interactive applications.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            This page is also still WIP, come back later for detailed introduction, links to paper, code and more! 
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
