<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <meta name="title" content="ShapeCraft: LLM Agents for Structured, Textured and Interactive 3D Modeling - Shuyuan Zhang, Chenhan Jiang, Zuoou Li, Jiankang Deng">
  <meta name="description" content="We introduce ShapeCraft, a novel training-free multi-agent framework that generates structured, textured, and interactive 3D models from natural language.">
  <meta name="keywords" content="ShapeCraft, LLM Agents, 3D Modeling, Text-to-3D, Generative AI, Training-free, Multi-agent Systems, Computer Vision, Graphics, AI Research">
  <meta name="author" content="Shuyuan Zhang, Chenhan Jiang, Zuoou Li, Jiankang Deng">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <!-- TODO: Replace with your institution or lab name | ask chenhan or jiankang about this-->
  <meta property="og:site_name" content="Imperial College London">
  <meta property="og:title" content="ShapeCraft: LLM Agents for Structured, Textured and Interactive 3D Modeling">
  <meta property="og:description" content="We introduce ShapeCraft, a novel training-free multi-agent framework that generates structured, textured, and interactive 3D models from natural language.">
  <meta property="og:url" content="https://sanbingyouyong.github.io/shapecraft/">
  <meta property="og:image" content="https://sanbingyouyong.github.io/shapecraft/static/images/teaser_1200x630.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="ShapeCraft: LLM Agents for Structured, Textured and Interactive 3D Modeling - Research Preview">
  <!-- TODO: time?  -->
  <meta property="article:published_time" content="2025-10-21T00:00:00.000Z">
  <meta property="article:author" content="Shuyuan Zhang">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="ShapeCraft">
  <meta property="article:tag" content="LLM Agents">
  <!-- TODO: can we have this many? -->
  <meta property="article:tag" content="3D Modeling">
  <meta property="article:tag" content="Text-to-3D">
  <meta property="article:tag" content="Generative AI">
  <meta property="article:tag" content="Training-free">
  <meta property="article:tag" content="Multi-agent Systems">
  <meta property="article:tag" content="Computer Vision">
  <meta property="article:tag" content="Graphics">
  <meta property="article:tag" content="AI Research">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@imperialcollege">
  <!-- TODO: Replace with first author's Twitter handle | is this bad...? -->
  <meta name="twitter:creator" content="@RayZhangSBYY">
  <meta name="twitter:title" content="ShapeCraft: LLM Agents for Structured, Textured and Interactive 3D Modeling">
  <meta name="twitter:description" content="We introduce ShapeCraft, a novel training-free multi-agent framework that generates structured, textured, and interactive 3D models from natural language.">
  <meta name="twitter:image" content="https://sanbingyouyong.github.io/shapecraft/static/images/teaser_1200x630.png">
  <meta name="twitter:image:alt" content="ShapeCraft: LLM Agents for Structured, Textured and Interactive 3D Modeling - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="ShapeCraft: LLM Agents for Structured, Textured and Interactive 3D Modeling">
  <meta name="citation_author" content="Zhang, Shuyuan">
  <meta name="citation_author" content="Jiang, Chenhan">
  <meta name="citation_author" content="Li, Zuoou">
  <meta name="citation_author" content="Deng, Jiankang">
  <meta name="citation_publication_date" content="2025">
  <meta name="citation_conference_title" content="NeurIPS 2025">
  <meta name="citation_pdf_url" content="https://sanbingyouyong.github.io/shapecraft/static/pdfs/shapecraft_camera_ready.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <title>ShapeCraft: LLM Agents for Structured, Textured and Interactive 3D Modeling - Shuyuan Zhang, Chenhan Jiang, Zuoou Li, Jiankang Deng | Academic Research</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
   <!-- TODO: check what date to use as publication date | social image | bibtex from arxiv to neurips |  -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "ShapeCraft: LLM Agents for Structured, Textured and Interactive 3D Modeling",
    "description": "We introduce ShapeCraft, a novel training-free multi-agent framework that generates structured, textured, and interactive 3D models from natural language.",
    "author": [
      {
        "@type": "Person",
        "name": "Shuyuan Zhang",
        "affiliation": {
          "@type": "Organization",
          "name": "Imperial College London"
        }
      },
      {
        "@type": "Person",
        "name": "Chenhan Jiang",
        "affiliation": {
          "@type": "Organization",
          "name": "Hong Kong University of Science and Technology"
        }
      },
      {
        "@type": "Person",
        "name": "Zuoou Li",
        "affiliation": {
          "@type": "Organization",
          "name": "Imperial College London"
        }
      },
      {
        "@type": "Person",
        "name": "Jiankang Deng",
        "affiliation": {
          "@type": "Organization",
          "name": "Imperial College London"
        }
      }
    ],
    "datePublished": "2025-10-21",
    "publisher": {
      "@type": "Organization",
      "name": "NeurIPS 2025"
    },
    "url": "https://sanbingyouyong.github.io/shapecraft/",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["ShapeCraft", "LLM Agents", "3D Modeling", "Text-to-3D", "Generative AI", "Training-free", "Multi-agent Systems", "Computer Vision", "Graphics", "AI Research"],
    "abstract": "3D generation from natural language offers significant potential to reduce expert manual modeling efforts and enhance accessibility to 3D assets. However, existing methods often yield unstructured meshes and exhibit poor interactivity, making them impractical for artistic workflows. To address these limitations, we represent 3D assets as shape programs and introduce ShapeCraft, a novel multi-agent framework for text-to-3D generation. At its core, we propose a Graph-based Procedural Shape (GPS) representation that decomposes complex natural language into a structured graph of sub-tasks, thereby facilitating accurate LLM comprehension and interpretation of spatial relationships and semantic shape details. Specifically, LLM agents hierarchically parse user input to initialize GPS, then iteratively refine procedural modeling and painting to produce structured, textured, and interactive 3D assets. Qualitative and quantitative experiments demonstrate ShapeCraft's superior performance in generating geometrically accurate and semantically rich 3D assets compared to existing LLM-based agents. We further show the versatility of ShapeCraft through examples of animated and user-customized editing, highlighting its potential for broader interactive applications.",
    "citation": "@misc{zhang2025shapecraftllmagentsstructured,
      title={ShapeCraft: LLM Agents for Structured, Textured and Interactive 3D Modeling}, 
      author={Shuyuan Zhang and Chenhan Jiang and Zuoou Li and Jiankang Deng},
      year={2025},
      eprint={2510.17603},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2510.17603}, 
}",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://sanbingyouyong.github.io/shapecraft/"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "Text-to-3D Generation"
      },
      {
        "@type": "Thing", 
        "name": "LLM Agents"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "Imperial College London",
    "url": "https://www.imperial.ac.uk/",
    "logo": "https://sanbingyouyong.github.io/shapecraft/static/images/favicon.ico",
    "sameAs": [
      "https://twitter.com/RayZhangSBYY",
      "https://github.com/SanBingYouYong"
    ]
  }
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <!-- NOTE: removed the more works drop down as I have none | TODO: ask chenhen or jiankang for more work ad here -->

  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">ShapeCraft: LLM Agents for Structured, Textured and Interactive 3D Modeling</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://sanbingyouyong.github.io" target="_blank">Shuyuan Zhang</a><sup>1,*</sup>,</span>
              <span class="author-block">
                <a href="https://jiangchenhan.github.io/" target="_blank">Chenhan Jiang</a><sup>2,*</sup>,</span>
              <span class="author-block">
                <a href="https://leo9344.github.io/" target="_blank">Zuoou Li</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://jiankangdeng.github.io" target="_blank">Jiankang Deng</a><sup>1</sup></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Imperial College London<br><sup>2</sup>Hong Kong University of Science and Technology<br>NeurIPS 2025</span>
              <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
            </div>

            <div class="column has-text-centered">
                    <div class="publication-links">
                      <span class="link-block">
                        <a href="https://sanbingyouyong.github.io/shapecraft/static/pdfs/shapecraft_camera_ready.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- TODO: GitHub Repo with cleaned up code -->
                  <span class="link-block">
                    <a href="https://github.com/SanBingYouYong/shapecraft" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <span class="link-block">
                  <a href="https://arxiv.org/abs/2510.17603" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body has-text-centered">
            <img src="./static/images/teaser.png" alt="ShapeCraft Teaser" style="max-width:100%; height:auto;">
            <h2 class="subtitle has-text-centered">
                We introduce <b>ShapeCraft</b>, a novel training-free multi-agent framework that generates structured, textured, and interactive 3D models from natural language.
            </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            3D generation from natural language offers significant potential to reduce expert manual modeling efforts and enhance accessibility to 3D assets. However, existing methods often yield unstructured meshes and exhibit poor interactivity, making them impractical for artistic workflows. To address these limitations, we represent 3D assets as shape programs and introduce ShapeCraft, a novel multi-agent framework for text-to-3D generation.
          </p>
          <p>
            At its core, we propose a Graph-based Procedural Shape (GPS) representation that decomposes complex natural language into a structured graph of sub-tasks, thereby facilitating accurate LLM comprehension and interpretation of spatial relationships and semantic shape details. Specifically, LLM agents hierarchically parse user input to initialize GPS, then iteratively refine procedural modeling and painting to produce structured, textured, and interactive 3D assets.
          </p>
          <p>
            Qualitative and quantitative experiments demonstrate ShapeCraft's superior performance in generating geometrically accurate and semantically rich 3D assets compared to existing LLM-based agents. We further show the versatility of ShapeCraft through examples of animated and user-customized editing, highlighting its potential for broader interactive applications.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Method Figure-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body has-text-centered">
    <h2 class="title is-3">Method</h2>
            <img src="./static/images/fig2_method.png" alt="ShapeCraft Methodology" style="max-width:100%; height:auto;">
            <p class="content has-text-centered">
                Given a shape description, the <b>Parser</b> agent hierarchically decomposes the shape and initializes <b>Graph-based Procedural Shape</b> representation. Then, each node is iteratively modeled by updating its code snippet using a multi-path strategy, with reinforcement from the <b>Coder</b> and <b>Evaluator</b> agents. Finally, a component-aware score distillation process learns a texture field from the resulting mesh to produce textured results.
            </p>
    </div>
  </div>
</section>
<!-- End method figure -->

<!-- Image carousel for qualitative comparisons -->
<section class="hero is-small">
<div class="hero-body">
<div class="container">
      <h2 class="title is-3 has-text-centered">Qualitative Results</h2>
  <div id="results-carousel" class="carousel results-carousel">
      <div class="item">
        <img src="static/images/fig4_rawmesh.png" alt="Raw Mesh Comparisons" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
          Qualitative comparison of raw mesh against LLM-based methods.
        </h2>
      </div>
      <div class="item">
        <img src="static/images/fig3_textured.png" alt="Textured Mesh Comparisons" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
          Qualitative comparison with optimization-based method.
        </h2>
      </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->

<!-- Image carousel for animation and editing -->
<section class="hero is-small">
<div class="hero-body">
<div class="container">
      <h2 class="title is-3 has-text-centered">Post-modeling Editing & Animation</h2>
  <div id="results-carousel" class="carousel results-carousel">
      <div class="item">
        <img src="static/images/fig14_editing.png" alt="Post-modeling Edits" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
          ShapeCraft produces editable shape programs that are editing-friendly both by LLMs and users.
        </h2>
      </div>
      <div class="item">
        <img src="static/images/fig6_animation.png" alt="Post-modeling Animation" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
          Benefiting from clear component structure, LLMs can be easily prompted to generate animations from exirting shape programs. 
        </h2>
      </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->

<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <!-- TODO: Add poster image for better preview -->
          <video poster="" id="video1" controls muted loop height="100%" preload="metadata">
            <!-- Your video file here -->
            <source src="static/videos/animation_fridge.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <!-- TODO: Add poster image for better preview -->
          <video poster="" id="video2" controls muted loop height="100%" preload="metadata">
            <!-- Your video file here -->
            <source src="static/videos/animation_laptop.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End video carousel -->

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@misc{zhang2025shapecraftllmagentsstructured,
      title={ShapeCraft: LLM Agents for Structured, Textured and Interactive 3D Modeling}, 
      author={Shuyuan Zhang and Chenhan Jiang and Zuoou Li and Jiankang Deng},
      year={2025},
      eprint={2510.17603},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2510.17603}, 
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
