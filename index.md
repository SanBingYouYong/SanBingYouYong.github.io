# ZHANG Shuyuan
A dedicated Computer Science graduate from the University of Edinburgh, currently pursuing an MSc in Advanced Computing at Imperial College London. With a solid background in **Computer Vision**, **Computer Graphics**, and **Natural Language Processing**, he has gained valuable experience in various technical domains, including *digital humans* and *large language models*.

## TL;DR
### CV/CG
- UoE Bachelor Dissertation: *Inverse Procedural Modeling: from Sketches to Buildings*
    - DAG based on Blender's geometry nodes as procedural shape program
    - Synthetic data generation through custom distortion&render pipeline
    - Encoder-decoder & Multi-task decoders neural network to predict shape parameters
    - Blender add-on as user interface
- took all (both) CG courses available at UoE: 
    - C++ Ray Tracer
    - Mesh Reconstructionfrom point clouds, Discrete Analysis and Parameterization

### NLP
- UoE NLP Coursess: *Foundations of Natural Language Processing* & *Natural Language Understanding, Generation and Machine Translation*
    - from *N-gram, Bayesian probabilities* to *RNN, GRU, LSTM* and finally *Transformer and Attention* mechanism
- NLP for games: built Stellaris namelist mod based on Ngram probabilities computed in a Chinese poetry dataset (500+ subs!)

### LLMs
- no money so focused on applications: 
    - Prompt Engineering, Multi-agent systems, OpenAI API, Ollama API
    - Task breakdown for better performance and robustness via designing and implementing Multi-agent systems
    - Generate fine-tune data for low-resource tasks
    - Deployed on remote server [QAnything](https://github.com/netease-youdao/QAnything) to serve as a LLM backend with knowledge base

### Digital Humans
- Deployed on remote server, extended and contributed to the open-source metahuman framework [Linly_Talker](https://github.com/Kedreamix/Linly-Talker), working with QAnything as an extra method to generate speech text for digital humans
- Deployed on remote server [GPT-SoVITS](https://github.com/RVC-Boss/GPT-SoVITS) to fine-tune models for voice cloning
- Deployed on remote server [metahuman-stream](https://github.com/lipku/metahuman-stream) as a real-time digital human streaming method

### Internet of Things
- UoE Course: *Principles and Design of IoT Systems*
    - Collect human activity data through wearable devices
    - Design, implement and train neural networks (CNN, RNN, LSTM with model ensembling) to identify activity and respiratory symptoms
    - Develop Android App to deploy trained models, connect to sensors via Bluetooth and classify human activities /respiratory symptoms in real-time

### System Engineering
- Group Project: A domino-placing robot based on TurtleBot, Lego motors, 3D printed parts and an Android App for Bluetooth connection to the robot for the course *System Design Project*
    - Designed the domino-reloading and automatic placement mechanism
    - Designed and modelled the 3D printed parts
    - Wrote Python scripts to control the Lego motors
    - Coordinated Android App development
    - Designed and implemented the communication method between server, robot and the app
